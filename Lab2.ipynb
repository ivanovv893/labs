{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0a72c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Прочитайте главы 4-6 из книги \"Spark: The Definitive Guide\".\n",
    "- Загрузите датасет из предыдущей лабораторной работы:\n",
    "    - https://www.kaggle.com/datasets/sveta151/tiktok-popular-songs-2022\n",
    "- Выполните задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a814fb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/28 12:29:47 WARN Utils: Your hostname, student-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "22/10/28 12:29:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/28 12:29:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Создаем SparkSession\n",
    "import mappings as mappings\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\")\\\n",
    "    .appName('SparkLab2')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Загружаем датасет.\n",
    "tiktokData0 = spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"/home/student/Work/Labs/TikTok_songs_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa83d79",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "№1: В столбце \"loudness\" переведите значения из дБ в проценты громкости. Выведите топ10 самых громких песен.\n",
    "\n",
    "|          track_name|               album|        artist_name|loudness|\n",
    "|--------------------|--------------------|-------------------|--------|\n",
    "|          Astronomia|          Astronomia|           Vicetone|      55|\n",
    "|     Sweater Weather|         I Love You.|  The Neighbourhood|      52|\n",
    "|          Dandelions|          Safe Haven|            Ruth B.|      51|\n",
    "|1, 2, 3 (feat. Ja...|1, 2, 3 (feat. Ja...|        Sofía Reyes|      49|\n",
    "|   Beauty And A Beat|   Beauty And A Beat|              Other|      49|\n",
    "|Being Good Is Boring|Being Good Is Boring|              Other|      48|\n",
    "|Wellerman - Sea S...|Wellerman (Sea Sh...|       Nathan Evans|      47|\n",
    "|           Thot Shit|           Thot Shit|Megan Thee Stallion|      45|\n",
    "|Friday (feat. Muf...|Friday (feat. Muf...|              Riton|      45|\n",
    "|               Hawái|        PAPI JUANCHO|             Maluma|      45|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed5f3f3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-------------------+\n",
      "|          track_name|               album|        artist_name|           loudness|\n",
      "+--------------------+--------------------+-------------------+-------------------+\n",
      "|          Astronomia|          Astronomia|           Vicetone| 0.1621063398155203|\n",
      "|     Sweater Weather|         I Love You.|  The Neighbourhood|0.14354894333536555|\n",
      "|          Dandelions|          Safe Haven|            Ruth B.|0.12959850747551394|\n",
      "|1, 2, 3 (feat. Ja...|1, 2, 3 (feat. Ja...|        Sofía Reyes|0.11651987230250002|\n",
      "|   Beauty And A Beat|   Beauty And A Beat|             Glamii|0.11643941101974166|\n",
      "|Being Good Is Boring|Being Good Is Boring|          Jena Rose|0.11033162127669813|\n",
      "|Wellerman - Sea S...|Wellerman (Sea Sh...|       Nathan Evans|0.10556015032159294|\n",
      "|           Thot Shit|           Thot Shit|Megan Thee Stallion|0.09392906516183994|\n",
      "|Friday (feat. Muf...|Friday (feat. Muf...|              Riton|0.09392906516183994|\n",
      "|      Break My Heart|    Future Nostalgia|           Dua Lipa|0.09328246202539883|\n",
      "+--------------------+--------------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from math import log10\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "tiktokData1 = tiktokData0.withColumn(\"loudness\", (100*10)**(col(\"loudness\")/10))\\\n",
    "\n",
    "tiktokData1.sort(desc(\"loudness\")).select(\"track_name\", \"album\", \"artist_name\", \"loudness\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8b3e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "№2: Получите имена соисполнителей из названий песен. Вынесите их в отдельный столбец. Удалите информацию о соисполнителях из названий треков.\n",
    "\n",
    "|track_name                                     |artist_name      |feat                       |\n",
    "|-----------------------------------------------|-----------------|---------------------------|\n",
    "|INDUSTRY BABY                                  |Lil Nas X        |Jack Harlow                |\n",
    "|Left and Right (Charlie Puth) - Sped Up Version|sped up nightcore|Jung Kook of BTS           |\n",
    "|Bam Bam                                        |Camila Cabello   |Ed Sheeran                 |\n",
    "|Down Under                                     |Luude            |Colin Hay                  |\n",
    "|1, 2, 3                                        |Sofía Reyes      |Jason Derulo & De La Ghetto|\n",
    "|Chaa Chaa Chaa                                 |Girll Codee      |HoodCelebrityy             |\n",
    "\n",
    "<div style=\"text-align: center\"> only showing top 6 rows </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c47f574d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+---------------+---------------------------+\n",
      "|track_name                                       |artist_name    |feat                       |\n",
      "+-------------------------------------------------+---------------+---------------------------+\n",
      "|STAY                                             |The Kid LAROI  |Justin Bieber              |\n",
      "|Enemy  - from the series Arcane League of Legends|Imagine Dragons|JID                        |\n",
      "|Flex On My Ex                                    |KillBunk       |Bankrol Hayden             |\n",
      "|INDUSTRY BABY                                    |Lil Nas X      |Jack Harlow                |\n",
      "|Cooped Up                                        |Post Malone    |Roddy Ricch                |\n",
      "|Bam Bam                                          |Camila Cabello |Ed Sheeran                 |\n",
      "|Down Under                                       |Luude          |Colin Hay                  |\n",
      "|1, 2, 3                                          |Sofía Reyes    |Jason Derulo & De La Ghetto|\n",
      "|Chaa Chaa Chaa                                   |Girll Codee    |HoodCelebrityy             |\n",
      "|Running To You                                   |VINAI          |Caden                      |\n",
      "|SAD GIRLZ LUV MONEY Remix                        |Amaarae        |Kali Uchis and Moliy       |\n",
      "|edamame                                          |bbno$          |Rich Brian                 |\n",
      "|Kiss Me More                                     |Doja Cat       |SZA                        |\n",
      "|Beautiful Mistakes                               |Maroon 5       |Megan Thee Stallion        |\n",
      "|Peaches                                          |Justin Bieber  |Daniel Caesar & Giveon     |\n",
      "|Levitating                                       |Dua Lipa       |DaBaby                     |\n",
      "|Bundles                                          |Kayla Nicole   |Taylor Girlz               |\n",
      "|Friday  - Dopamine Re-Edit                       |Riton          |Mufasa & Hypeman           |\n",
      "|Mood                                             |24kGoldn       |iann dior                  |\n",
      "|Best Friend                                      |Saweetie       |Doja Cat                   |\n",
      "+-------------------------------------------------+---------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "tiktokData2 = tiktokData1\\\n",
    "    .withColumn('feat', regexp_extract(col('track_name'), '(.*)\\((feat\\\\. |with )(.+)\\)', 3))\\\n",
    "    .withColumn('track_name', regexp_replace('track_name', '\\((feat\\\\. |with )(.+)\\)', ''))\n",
    "\n",
    "tiktokData2.filter(length(col('feat')) > 1).select(\"track_name\", \"artist_name\", \"feat\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cb42e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "№3: Разделите строки с соисполнителями по символу '&'. Для каждой песни соберите всех исполнителей в один массив. Отсортируйте песни по количеству исполнителей и названиям песен.\n",
    "\n",
    "|track_name                       |artist_names                             |\n",
    "|---------------------------------|-----------------------------------------|\n",
    "|1, 2, 3                          |[Sofía Reyes, Jason Derulo, De La Ghetto]|\n",
    "|For The Night                    |[Pop Smoke, Lil Baby, DaBaby]            |\n",
    "|Friday - Dopamine Re-Edit        |[Riton, Mufasa, Hypeman]                 |\n",
    "|Peaches                          |[Justin Bieber, Daniel Caesar, Giveon]   |\n",
    "|Bam Bam                          |[Camila Cabello, Ed Sheeran]             |\n",
    "|Banana - DJ FLe - Minisiren Remix|[Conkarah, Shaggy]                       |\n",
    "\n",
    "<div style=\"text-align: center\"> only showing top 6 rows </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a48faba9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+------------------------------------------+\n",
      "|track_name                                       |artist_names                              |\n",
      "+-------------------------------------------------+------------------------------------------+\n",
      "|STAY                                             |[The Kid LAROI, Justin Bieber]            |\n",
      "|Enemy  - from the series Arcane League of Legends|[Imagine Dragons, JID]                    |\n",
      "|Flex On My Ex                                    |[KillBunk, Bankrol Hayden]                |\n",
      "|INDUSTRY BABY                                    |[Lil Nas X, Jack Harlow]                  |\n",
      "|Cooped Up                                        |[Post Malone, Roddy Ricch]                |\n",
      "|Bam Bam                                          |[Camila Cabello, Ed Sheeran]              |\n",
      "|Down Under                                       |[Luude, Colin Hay]                        |\n",
      "|1, 2, 3                                          |[Sofía Reyes, Jason Derulo & De La Ghetto]|\n",
      "|Chaa Chaa Chaa                                   |[Girll Codee, HoodCelebrityy]             |\n",
      "|Running To You                                   |[VINAI, Caden]                            |\n",
      "|SAD GIRLZ LUV MONEY Remix                        |[Amaarae, Kali Uchis and Moliy]           |\n",
      "|We Know                                          |[JAM, Philly]                             |\n",
      "|Jiggle Jiggle                                    |[Duke, Jones]                             |\n",
      "|Looking for Love                                 |[Asketa, Natan Chaim]                     |\n",
      "|edamame                                          |[bbno$, Rich Brian]                       |\n",
      "|Kiss Me More                                     |[Doja Cat, SZA]                           |\n",
      "|Beautiful Mistakes                               |[Maroon 5, Megan Thee Stallion]           |\n",
      "|Peaches                                          |[Justin Bieber, Daniel Caesar & Giveon]   |\n",
      "|Levitating                                       |[Dua Lipa, DaBaby]                        |\n",
      "|Bundles                                          |[Kayla Nicole, Taylor Girlz]              |\n",
      "+-------------------------------------------------+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import array_union\n",
    "from pyspark.sql.functions import array\n",
    "from pyspark.sql.functions import size\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "tiktokData3 = tiktokData2.withColumn('artist_names',\n",
    "                                     array_union(split(col('artist_name'), ' & '), array(col('feat'))))\n",
    "tiktokData3 = tiktokData3.withColumn('artist_names',\n",
    "                                     F.expr('filter(artist_names, x -> x is not null and x != \"\")'))\n",
    "\n",
    "tt4 = tiktokData3\n",
    "\n",
    "tiktokData3.filter(size(col(\"artist_names\")) > 1).select(\"track_name\", \"artist_names\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71a168",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "№4: Выведите список песен Doja Cat.\n",
    "\n",
    "|  track_name|               album|        artist_names|\n",
    "|------------|--------------------|--------------------|\n",
    "|       Woman|          Planet Her|          [Doja Cat]|\n",
    "|Kiss Me More|Kiss Me More (fea...|     [Doja Cat, SZA]|\n",
    "|Need to Know|          Planet Her|          [Doja Cat]|\n",
    "|  Ain't Shit|          Planet Her|          [Doja Cat]|\n",
    "|   You Right|          Planet Her|          [Doja Cat]|\n",
    "| Best Friend|Best Friend (feat...|[Saweetie, Doja Cat]|\n",
    "|       Freak|               Freak|          [Doja Cat]|\n",
    "|  Boss Bitch|          Boss Bitch|          [Doja Cat]|\n",
    "|      Say So|            Hot Pink|          [Doja Cat]|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "689cc597",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------------------------+-------------------------+\n",
      "|track_name   |album                                  |artist_names             |\n",
      "+-------------+---------------------------------------+-------------------------+\n",
      "|Woman        |Planet Her                             |[Doja Cat]               |\n",
      "|Kiss Me More |Kiss Me More (feat. SZA)               |[Doja Cat, SZA]          |\n",
      "|Need to Know |Planet Her                             |[Doja Cat]               |\n",
      "|Ain't Shit   |Planet Her                             |[Doja Cat]               |\n",
      "|You Right    |Planet Her                             |[Doja Cat]               |\n",
      "|Best Friend  |Best Friend (feat. Doja Cat) [Remix EP]|[Saweetie, Doja Cat]     |\n",
      "|motive       |Positions (Deluxe)                     |[Ariana Grande, Doja Cat]|\n",
      "|Freak        |Freak                                  |[Doja Cat]               |\n",
      "|Boss Bitch   |Boss Bitch                             |[Doja Cat]               |\n",
      "|Say So       |Hot Pink                               |[Doja Cat]               |\n",
      "+-------------+---------------------------------------+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, array_contains\n",
    "\n",
    "tiktokData3.select(\"track_name\", \"album\", \"artist_names\").where(array_contains(col('artist_names'), 'Doja Cat')).show(\n",
    "    truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf9daf5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "№5: Выведите таблицу с исполнителями и количеством их треков в порядке уменьшения.\n",
    "\n",
    "|   artist_name|count|\n",
    "|--------------|-----|\n",
    "|      Doja Cat|    9|\n",
    "|        Coopex|    6|\n",
    "|     Dame Dame|    5|\n",
    "|Alex Alexander|    4|\n",
    "|       YES YES|    4|\n",
    "|     Lil Nas X|    4|\n",
    "\n",
    "\n",
    "<div style=\"text-align: center\"> only showing top 6 rows </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6221c4a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|   artist_name|count|\n",
      "+--------------+-----+\n",
      "|      Doja Cat|    8|\n",
      "|        Coopex|    6|\n",
      "|     Dame Dame|    5|\n",
      "|Alex Alexander|    4|\n",
      "|       YES YES|    4|\n",
      "|     Lil Nas X|    4|\n",
      "+--------------+-----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tiktokData3.groupby(col('artist_name')).count().orderBy('count', ascending=False).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11fa46",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "№6: Замените имена всех исполнителей, популярность которых неизвестна или меньше 50, на \"Other\". Отсортируйте треки по количеству исполнителей и популярности.\n",
    "\n",
    "|track_name               |artist_names                   |track_pop|\n",
    "|-------------------------|-------------------------------|---------|\n",
    "|Peaches                  |[Justin Bieber, Other, Other]  |86       |\n",
    "|Friday - Dopamine Re-Edit|[Riton, Other, Other]          |83       |\n",
    "|1, 2, 3                  |[Sofía Reyes, Other, Other]    |82       |\n",
    "|For The Night            |[Pop Smoke, Other, DaBaby]     |80       |\n",
    "|Jimmy Cooks              |[Drake, Other]                 |92       |\n",
    "|INDUSTRY BABY            |[Lil Nas X, Jack Harlow]       |86       |\n",
    "|Levitating               |[Dua Lipa, DaBaby]             |85       |\n",
    "|Bam Bam                  |[Camila Cabello, Ed Sheeran]   |83       |\n",
    "|Beautiful Mistakes       |[Maroon 5, Megan Thee Stallion]|82       |\n",
    "|Kiss Me More             |[Doja Cat, SZA]                |82       |\n",
    "\n",
    "<div style=\"text-align: center\"> only showing top 10 rows </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47dc6439",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/student/Work/lib/python3.10/site-packages/pyspark/serializers.py\", line 458, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "  File \"/home/student/Work/lib/python3.10/site-packages/pyspark/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/home/student/Work/lib/python3.10/site-packages/pyspark/cloudpickle/cloudpickle_fast.py\", line 602, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/home/student/Work/lib/python3.10/site-packages/pyspark/context.py\", line 447, in __getnewargs__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/serializers.py:458\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/cloudpickle/cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[1;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/cloudpickle/cloudpickle_fast.py:602\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/context.py:447\u001b[0m, in \u001b[0;36mSparkContext.__getnewargs__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getnewargs__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# This method is called when attempting to pickle SparkContext, which is always an error:\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt appears that you are attempting to reference SparkContext from a broadcast \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable, action, or transformation. SparkContext can only be used on the driver, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot in code that it run on workers. For more information, see SPARK-5063.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect_list, avg\n\u001b[1;32m      5\u001b[0m change_names_udf \u001b[38;5;241m=\u001b[39m udf(\u001b[38;5;28;01mlambda\u001b[39;00m arr: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tiktokData3\u001b[38;5;241m.\u001b[39mfilter(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martist_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m x)\u001b[38;5;241m.\u001b[39magg(avg(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martist_pop\u001b[39m\u001b[38;5;124m\"\u001b[39m))) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arr],\n\u001b[1;32m      6\u001b[0m                    ArrayType(StringType()))\n\u001b[0;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m tiktokData3\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplaced_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mchange_names_udf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martist_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m res\u001b[38;5;241m.\u001b[39msort(desc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_pop\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplaced_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack_pop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/sql/udf.py:276\u001b[0m, in \u001b[0;36mUserDefinedFunction._wrapped.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, assigned\u001b[38;5;241m=\u001b[39massignments)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/sql/udf.py:249\u001b[0m, in \u001b[0;36mUserDefinedFunction.__call__\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    247\u001b[0m     judf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_judf(func)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m     judf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_judf\u001b[49m\n\u001b[1;32m    251\u001b[0m jPythonUDF \u001b[38;5;241m=\u001b[39m judf\u001b[38;5;241m.\u001b[39mapply(_to_seq(sc, cols, _to_java_column))\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/sql/udf.py:215\u001b[0m, in \u001b[0;36mUserDefinedFunction._judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_judf\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JavaObject:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# It is possible that concurrent access, to newly created UDF,\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# will initialize multiple UserDefinedPythonFunctions.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# This is unlikely, doesn't affect correctness,\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# and should have a minimal performance impact.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_judf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/sql/udf.py:224\u001b[0m, in \u001b[0;36mUserDefinedFunction._create_judf\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    221\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39m_getActiveSessionOrCreate()\n\u001b[1;32m    222\u001b[0m sc \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\n\u001b[0;32m--> 224\u001b[0m wrapped_func \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturnType\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m jdt \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mparseDataType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnType\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/sql/udf.py:50\u001b[0m, in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, returnType)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_function\u001b[39m(\n\u001b[1;32m     47\u001b[0m     sc: SparkContext, func: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any], returnType: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataTypeOrString\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JavaObject:\n\u001b[1;32m     49\u001b[0m     command \u001b[38;5;241m=\u001b[39m (func, returnType)\n\u001b[0;32m---> 50\u001b[0m     pickled_command, broadcast_vars, env, includes \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_for_python_RDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonFunction(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28mbytearray\u001b[39m(pickled_command),\n\u001b[1;32m     54\u001b[0m         env,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m         sc\u001b[38;5;241m.\u001b[39m_javaAccumulator,\n\u001b[1;32m     60\u001b[0m     )\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/rdd.py:3345\u001b[0m, in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   3342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_python_RDD\u001b[39m(sc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkContext\u001b[39m\u001b[38;5;124m\"\u001b[39m, command: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mbytes\u001b[39m, Any, Any, Any]:\n\u001b[1;32m   3343\u001b[0m     \u001b[38;5;66;03m# the serialized command will be compressed by broadcast\u001b[39;00m\n\u001b[1;32m   3344\u001b[0m     ser \u001b[38;5;241m=\u001b[39m CloudPickleSerializer()\n\u001b[0;32m-> 3345\u001b[0m     pickled_command \u001b[38;5;241m=\u001b[39m \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3346\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pickled_command) \u001b[38;5;241m>\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetBroadcastThreshold(sc\u001b[38;5;241m.\u001b[39m_jsc):  \u001b[38;5;66;03m# Default 1M\u001b[39;00m\n\u001b[1;32m   3348\u001b[0m         \u001b[38;5;66;03m# The broadcast will have same life cycle as created PythonRDD\u001b[39;00m\n",
      "File \u001b[0;32m~/Work/lib/python3.10/site-packages/pyspark/serializers.py:468\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    466\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not serialize object: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, emsg)\n\u001b[1;32m    467\u001b[0m print_exec(sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m--> 468\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPicklingError(msg)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063."
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import collect_list, avg\n",
    "\n",
    "\n",
    "change_names_udf = udf(lambda arr: [\"Other\" if tiktokData3.filter(col(\"artist_name\") == x).agg(avg(col(\"artist_pop\"))) < 50 else x for x in arr],\n",
    "                   ArrayType(StringType()))\n",
    "\n",
    "res = tiktokData3.withColumn('replaced_names', change_names_udf(col('artist_names')))\n",
    "\n",
    "res.sort(desc('track_pop')).select(\"track_name\", \"replaced_names\", \"track_pop\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2652733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
